{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loadtest5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsl01/income2/blob/master/loadtest5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiWAmyw5t-Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title           Drive Access                #\n",
        "###############################################\n",
        "\n",
        "\n",
        "todo = \"deal with non numeric columns amd the missing data \"\n",
        "\n",
        "print (todo)\n",
        "\n",
        "print ('drive access')\n",
        "\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "!ls '/content/gdrive/My Drive/income'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKufID57CPa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYtxV4WcsVHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title             Imports                   #\n",
        "###############################################\n",
        "\n",
        "\n",
        "print ('imports')\n",
        "\n",
        "from datetime import datetime as dt\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# import sklearn as skl\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network as nnet\n",
        "from sklearn import svm\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# include the TensorFlow libraries \n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "# plotting utilities\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D as a3d\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import SGD, Adam \n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zy_Aii8cz8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcetgwSpe6re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title         myscale() function              #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# define a function to take a pair of series and return a scaled 0-1 pair \n",
        "# using the min & max from both to apply the scale.\n",
        "# typically used to pass a pair of cols from A TRAIN / TEST set\n",
        "# and return then scaled values in a similar pair of series.\n",
        "\n",
        "def myscale ( trainseries, testseries ) : \n",
        "\n",
        "  # create the return series\n",
        "  # trainscale = pd.Series ( np.zeros(len(trainseries)))\n",
        "  # testscale =  pd.Series ( np.zeros(len(testseries)))\n",
        "  \n",
        "  # print ('in myscale')\n",
        "\n",
        "  # print (\"Initial : \" )\n",
        "  # print (\"  max : \")\n",
        "  # print (\"    \", trainseries.max(), testseries.max())\n",
        "  maxseries = max(trainseries.max(), testseries.max())\n",
        "  # print (\"    \", maxseries) \n",
        "\n",
        "  # print (\"  min : \")\n",
        "  # print (\"    \",trainseries.min(), testseries.min())\n",
        "  minseries = min(trainseries.min(), testseries.min())\n",
        "  # print (\"    \", minseries)\n",
        "\n",
        "  rangeseries = maxseries - minseries\n",
        "\n",
        "  trainscale = (trainseries - minseries)/ rangeseries\n",
        "  testscale = (testseries - minseries)/ rangeseries\n",
        "\n",
        "  # print (\"\\nEncoded : \" )\n",
        "  # print (\"  max : \")\n",
        "  # print (\"    \", trainscale.max(), testscale.max())\n",
        "  maxscale = max(trainscale.max(), testscale.max())\n",
        "  # print (\"    \", maxscale) \n",
        "\n",
        "  # print (\"  min : \")\n",
        "  # print (\"    \",trainscale.min(), testscale.min())\n",
        "  minscale = min(trainscale.min(), testscale.min())\n",
        "  # print (\"    \", minscale)\n",
        "\n",
        "  # print (trainscale.sum(), testscale.sum())\n",
        "\n",
        "  return (trainscale, testscale)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plvujs8C-Zfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L8_4LYEgaOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title           data loads                  #\n",
        "###############################################\n",
        "\n",
        "\n",
        "print ('data loads')\n",
        "\n",
        "print (\"train\")\n",
        "print(dt.now())\n",
        "training_path = \"/content/gdrive/My Drive/income/tcd-ml-1920-group-income-train.csv\"\n",
        "# print (\"nrows set to 100\")\n",
        "# train_df = pd.read_csv(training_path, nrows=10000)\n",
        "train_df = pd.read_csv(training_path)\n",
        "\n",
        "print (\"test\")\n",
        "print(dt.now())\n",
        "test_path = \"/content/gdrive/My Drive/income/tcd-ml-1920-group-income-test.csv\"\n",
        "# test_df = pd.read_csv(test_path, nrows=10000)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZhON4EZuQvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_df.shape)\n",
        "print (test_df.shape)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GjjmOk9_Ekf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\" train_df :\")\n",
        "print (train_df.columns)\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print (test_df.columns)\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-YMBOVjLtdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title           Column Renames              #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# dont like the col names - much easier with simple strings with no spaces.\n",
        "train_df.rename(columns = {\"Year of Record\" : \"Year\",\n",
        "                           \"Housing Situation\" : \"Housing\",\n",
        "                           \"Crime Level in the City of Employement\" : \"CrimeLevel\",\n",
        "                           \"Work Experience in Current Job [years]\" : \"WorkExp\",\n",
        "                           \"Satisfation with employer\" : \"Satisfaction\",\n",
        "                           \"Size of City\" : \"CitySize\",\n",
        "                           \"University Degree\" : \"Degree\",\n",
        "                           \"Wears Glasses\" : \"Glasses\",\n",
        "                           \"Hair Color\" : \"Hair\",\n",
        "                           \"Body Height [cm]\" : \"Height\",\n",
        "                           \"Yearly Income in addition to Salary (e.g. Rental Income)\" : \"AdditionalIncome\",\n",
        "                           \"Total Yearly Income [EUR]\" : \"Income\"},\n",
        "                  inplace = True)\n",
        "\n",
        "test_df.rename( columns = {\"Year of Record\" : \"Year\",\n",
        "                           \"Housing Situation\" : \"Housing\",\n",
        "                           \"Crime Level in the City of Employement\" : \"CrimeLevel\",\n",
        "                           \"Work Experience in Current Job [years]\" : \"WorkExp\",\n",
        "                           \"Satisfation with employer\" : \"Satisfaction\",\n",
        "                           \"Size of City\" : \"CitySize\",\n",
        "                           \"University Degree\" : \"Degree\",\n",
        "                           \"Wears Glasses\" : \"Glasses\",\n",
        "                           \"Hair Color\" : \"Hair\",\n",
        "                           \"Body Height [cm]\" : \"Height\",\n",
        "                           \"Yearly Income in addition to Salary (e.g. Rental Income)\" : \"AdditionalIncome\",\n",
        "                           \"Total Yearly Income [EUR]\" : \"Income\"},\n",
        "                  inplace = True)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzXC-1Z7Nl_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\" train_df :\")\n",
        "print (train_df.columns)\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print (test_df.columns)\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGdRnOp-Ane",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.head())\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb0r7wSr-VBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( train_df.describe() )\n",
        "print (train_df[[\"Instance\", \"Year\", \"CrimeLevel\", \"Age\", \"CitySize\", \"Glasses\", \"Height\", \"Income\"]].describe() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3HcKA_v-lFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( train_df[['Satisfaction','Gender','Country','Profession','Degree','Hair','AdditionalIncome']].describe() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmKX36ckZORr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( train_df[['WorkExp']].describe() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVE_wKplbudB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( train_df[['Housing']].describe() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93yQSIRzcWeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "print('checking pearson and spearman corellations') \n",
        "\n",
        "\n",
        "\n",
        "x = np.array([1,2,3,4,5])\n",
        "y0 = np.array([1,1.4,1.7,2,2.1]) # aproximate roots\n",
        "y1 = np.array([2,4.2,6,7,10]) # aproximately linear\n",
        "y2 = np.array([0.9,4.1, 9.5, 17, 27]) # aproximate squares\n",
        "y3 = np.array([0.9,8.1, 27.5, 68, 133]) # aproximate cubes\n",
        "\n",
        "print (pearsonr(x,y0), spearmanr(x,y0))\n",
        "print (pearsonr(x,y1), spearmanr(x,y1))\n",
        "print (pearsonr(x,y2), spearmanr(x,y2))\n",
        "print (pearsonr(x,y3), spearmanr(x,y3))\n",
        "'''\n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9EUoA0yrcAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"run pearson and spearman analysis for our full numeric columns against the income result\")\n",
        "print (\"pearson test for linear correlation - spearman for monotonic corelation (which may not be linear) \\n\")\n",
        "\n",
        "# 'Instance', 'Year', 'Housing', 'CrimeLevel', 'WorkExp', 'Satisfaction',\n",
        "# 'Gender', 'Age', 'Country', 'CitySize', 'Profession', 'Degree',\n",
        "# 'Glasses', 'Hair', 'Height', 'AdditionalIncome', 'Income'\n",
        "\n",
        "print (\" 0 Instance : \",\n",
        "       pearsonr(train_df[ 'Instance'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Instance'], train_df['Income']),\n",
        "       \"  -  quite a high, but somewhat non linear corelation. Why ? \\n\")\n",
        "\n",
        "print (\" 1 Year has missing data. \\n\")\n",
        "# print (\"Year : \", pearsonr(train_df[ 'Year'], train_df['Income']))\n",
        "\n",
        "print (\" 2 Housing is categorical incl some numerical. \\n\")\n",
        "\n",
        "print (\" 3 CrimeLevel : \",\n",
        "       pearsonr(train_df[ 'CrimeLevel'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CrimeLevel'], train_df['Income']),\n",
        "       \"  -  Very little corelation. \\n\")\n",
        "\n",
        "print (\" 4 Age: \",\n",
        "       pearsonr(train_df[ 'Age'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Age'], train_df['Income']),\n",
        "       \"  -  Very little corelation. \\n\")\n",
        "\n",
        "print (\" 5 WorkExp is categorical incl some numerical. \\n\")\n",
        "\n",
        "print (\" 6 Satisfaction is categorical - with missing values. \\n\")\n",
        "\n",
        "print (\" 7 Gender is categorical. \\n\")\n",
        "\n",
        "print (\" 8 Country is categorical. \\n\")\n",
        "\n",
        "print (\" 9 CitySize : \",\n",
        "       pearsonr(train_df[ 'CitySize'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CitySize'], train_df['Income']),\n",
        "       \"  -  Slight correlation - but not linear. \\n\")\n",
        "\n",
        "print (\"10 Profession is categorical. \\n\")\n",
        "\n",
        "print (\"11 Degree is categorical. \\n\")\n",
        "\n",
        "print (\"12 Glasses : \",\n",
        "       pearsonr(train_df[ 'Glasses'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Glasses'], train_df['Income']),\n",
        "       \"  -  No correlation - drop the column it's just noise. \\n\")\n",
        "\n",
        "print (\"13 Hair is categorical. \\n\")\n",
        "\n",
        "print (\"14 Height : \",\n",
        "       pearsonr(train_df[ 'Height'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Height'], train_df['Income']),\n",
        "       \"  -  Almost no correlation - drop the column it's just noise. \\n\")\n",
        "\n",
        "print (\"15 AdditionalIncome is categorical incl some numerical. \\n\")\n",
        "\n",
        "print (\"16 Income : \",\n",
        "       pearsonr(train_df[ 'Income'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Income'], train_df['Income']),\n",
        "       \"  -  perfect correlation - just to test - it had better be! \\n\")\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp37ZbohmJBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            Instance                   #\n",
        "###############################################\n",
        "\n",
        "\n",
        "print (\" --------  Instance  -------\")\n",
        "# Instance \n",
        "# encode as a scaled value \n",
        "\n",
        "'''\n",
        "print (\"Initial : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.Instance.max(), test_df.Instance.max())\n",
        "maxInstance = max(train_df.Instance.max(), test_df.Instance.max())\n",
        "print (\"    \", maxInstance) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.Instance.min(), test_df.Instance.min())\n",
        "minInstance = min(train_df.Instance.min(), test_df.Instance.min())\n",
        "print (\"    \", minInstance)\n",
        "\n",
        "rangeInstance = maxInstance - minInstance\n",
        "train_df.loc[:, 'InstanceEnc'] = (train_df['Instance']-minInstance) / rangeInstance\n",
        "\n",
        "test_df.loc[:, 'InstanceEnc'] = (test_df['Instance']-minInstance) / rangeInstance\n",
        "\n",
        "print (\"\\nEncoded : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.InstanceEnc.max(), test_df.InstanceEnc.max())\n",
        "maxInstanceEnc = max(train_df.InstanceEnc.max(), test_df.InstanceEnc.max())\n",
        "print (\"    \", maxInstanceEnc) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.InstanceEnc.min(), test_df.InstanceEnc.min())\n",
        "minInstanceEnc = min(train_df.InstanceEnc.min(), test_df.InstanceEnc.min())\n",
        "print (\"    \", minInstanceEnc)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "train_df[ 'InstanceEnc'], test_df[ 'InstanceEnc'] = myscale ( train_df.Instance, test_df.Instance) \n",
        "\n",
        "print (\" 0 Instance : \",\n",
        "       pearsonr(train_df[ 'InstanceEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'InstanceEnc'], train_df['Income']),\n",
        "       \"  -  quite high, but somewhat non linear corelation. Why ? \\n\")\n",
        "\n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OraqOC6apQ1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hP5zdn0oNOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so go through the remaining columns - decide what to do with them \n",
        "# and then test the correlation between the treated value and the income\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dzjo4ytopWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            Year                       #\n",
        "###############################################\n",
        "\n",
        "\n",
        "print (\" --------  Year  -------\\n\")\n",
        "\n",
        "# missing data but otherwise numeric between 1940 and 2019 \n",
        "\n",
        "# lets fill with an out of range value and chart it \n",
        "# then look at the charts and correlations and decide on a strategy \n",
        "\n",
        "# done - fill with rounded mean 1979.0 (1979)\n",
        "\n",
        "train_df.Year.fillna(1979.0, inplace=True)\n",
        "\n",
        "test_df.Year.fillna(1979.0, inplace=True)\n",
        "\n",
        "print (\"train_df :\")\n",
        "print ( train_df['Year'].describe() )\n",
        "\n",
        "print(\"test_df :\")\n",
        "print (test_df['Year'].describe() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ml9NM3NlvlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMsNZjEhrXWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df['Year'].hist(bins=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl9G6X9KrxNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\" 1 Year : \",\n",
        "       pearsonr(train_df[ 'Year'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Year'], train_df['Income']),\n",
        "       \"  -  Good correlation - almost the same as Instance - slightly non linear. \\n\")\n",
        "\n",
        "# 1 Year :  (0.6310504764919517, 0.0) SpearmanrResult(correlation=0.8495098504454566, pvalue=0.0) - 1939 fillna\n",
        "# 1 Year :  (0.6317759175887114, 0.0) SpearmanrResult(correlation=0.8503274082842994, pvalue=0.0) - 2020 fillna\n",
        "# 1 Year :  (0.6353301585949168, 0.0) SpearmanrResult(correlation=0.854775189253737,  pvalue=0.0) - 1979.0 fillna ==> use this \n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMUobeMKq5Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode as a scaled value : \n",
        "\n",
        "# Year\n",
        "# encode as a scaled value \n",
        "\n",
        "'''\n",
        "print (\"Initial : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.Year.max(), test_df.Year.max())\n",
        "maxYear = max(train_df.Year.max(), test_df.Year.max())\n",
        "print (\"    \", maxYear) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.Year.min(), test_df.Year.min())\n",
        "minYear = min(train_df.Year.min(), test_df.Year.min())\n",
        "print (\"    \", minYear)\n",
        "\n",
        "rangeYear = maxYear - minYear\n",
        "train_df.loc[:, 'YearEnc'] = (train_df['Year']-minYear) / rangeYear\n",
        "\n",
        "test_df.loc[:, 'YearEnc'] = (test_df['Year']-minYear) / rangeYear\n",
        "\n",
        "print (\"\\nEncoded : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.YearEnc.max(), test_df.YearEnc.max())\n",
        "maxYearEnc = max(train_df.YearEnc.max(), test_df.YearEnc.max())\n",
        "print (\"    \", maxYearEnc) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.YearEnc.min(), test_df.YearEnc.min())\n",
        "minYearEnc = min(train_df.YearEnc.min(), test_df.YearEnc.min())\n",
        "print (\"    \", minYearEnc)\n",
        "'''\n",
        "\n",
        "train_df[ 'YearEnc'], test_df[ 'YearEnc'] = myscale ( train_df.Year, test_df.Year) \n",
        "\n",
        "print (\" 1 Year : \",\n",
        "       pearsonr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       \"  -  quite a high, but somewhat non linear corelation. Why ? \\n\")\n",
        "\n",
        "print ( train_df.YearEnc.sum(), test_df.YearEnc.sum() )\n",
        "# 523471.29113924055 184765.36708860757\n",
        "\n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl735YK2t5By",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            Housing                    #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# Housing\n",
        "\n",
        "print (\"train_df :\")\n",
        "print( train_df.Housing.unique() )\n",
        "\n",
        "print (\"test_df :\")\n",
        "print ( test_df.Housing.unique() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxcmeU_luuxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housingcount = 0\n",
        "\n",
        "print ('train_df')\n",
        "print (\"        mean       std-dev         count    max    min      Housing\")\n",
        "\n",
        "for i in train_df.Housing.unique() :\n",
        "  print (train_df.loc[train_df.Housing == i].Income.mean(),\n",
        "         train_df.loc[train_df.Housing == i].Income.std(),\n",
        "         train_df.loc[train_df.Housing == i].Instance.count(),\n",
        "         train_df.loc[train_df.Housing == i].Income.max(),\n",
        "         train_df.loc[train_df.Housing == i].Income.min(),\n",
        "         \" ---- \", i)\n",
        "  housingcount += train_df.loc[train_df.Housing == i].Instance.count()\n",
        "print('sum of counts : ', housingcount, \"\\n\")\n",
        "\n",
        "housingcounttest = 0\n",
        "print ('test_df')\n",
        "print (\"  count     Housing\")\n",
        "for i in test_df.Housing.unique() :\n",
        "  print (test_df.loc[test_df.Housing == i].Instance.count(),       \n",
        "         \" ---- \", i)\n",
        "  housingcounttest += test_df.loc[test_df.Housing == i].Instance.count()\n",
        "print('sum of counts : ',housingcounttest, \"\\n\")\n",
        "\n",
        "# use mean encoding - may adjust to a smoothed mean or James-Stein later\n",
        "\n",
        "#build a map and then use it \n",
        "mean_encode = train_df.groupby('Housing')['Income'].mean()\n",
        "\n",
        "print(type(mean_encode))\n",
        "print (mean_encode)\n",
        "\n",
        "extra_encode = pd.Series ([1.0, 2.0], index=[\"Avg_1\",\"Avg_2\"])\n",
        "\n",
        "mean_encode = mean_encode.append(extra_encode)\n",
        "\n",
        "print(type(mean_encode))\n",
        "print (mean_encode)\n",
        "\n",
        "\n",
        "train_df.loc[:, 'HousingEnc1'] = train_df['Housing'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'HousingEnc1'] = test_df['Housing'].map(mean_encode)\n",
        "\n",
        "print (train_df.columns)\n",
        "print (test_df.columns)\n",
        "\n",
        "print (\"\\n 17 HousingEnc1 : \",\n",
        "       pearsonr(train_df[ 'HousingEnc1'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'HousingEnc1'], train_df['Income']),\n",
        "       \"  -  good correlation - slightly non linear. \\n\")\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNilUWfMwfr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# encode as a scaled value \n",
        "\n",
        "'''\n",
        "print (\"Initial : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.HousingEnc1.max(), test_df.HousingEnc1.max())\n",
        "maxHousing = max(train_df.HousingEnc1.max(), test_df.HousingEnc1.max())\n",
        "print (\"    \", maxHousing) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.HousingEnc1.min(), test_df.HousingEnc1.min())\n",
        "minHousing = min(train_df.HousingEnc1.min(), test_df.HousingEnc1.min())\n",
        "print (\"    \", minHousing)\n",
        "\n",
        "rangeHousing = maxHousing - minHousing\n",
        "train_df.loc[:, 'HousingEnc'] = (train_df['HousingEnc1']-minHousing) / rangeHousing\n",
        "\n",
        "test_df.loc[:, 'HousingEnc'] = (test_df['HousingEnc1']-minHousing) / rangeHousing\n",
        "\n",
        "print (\"\\nEncoded : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.HousingEnc.max(), test_df.HousingEnc.max())\n",
        "maxHousingEnc = max(train_df.HousingEnc.max(), test_df.HousingEnc.max())\n",
        "print (\"    \", maxHousingEnc) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.HousingEnc.min(), test_df.HousingEnc.min())\n",
        "minHousingEnc = min(train_df.HousingEnc.min(), test_df.HousingEnc.min())\n",
        "print (\"    \", minHousingEnc)\n",
        "\n",
        "'''\n",
        "train_df[ 'HousingEnc'], test_df[ 'HousingEnc'] = myscale ( train_df.HousingEnc1, test_df.HousingEnc1 ) \n",
        "\n",
        "\n",
        "print (\" 2 Housing : \",\n",
        "       pearsonr(train_df[ 'HousingEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'HousingEnc'], train_df['Income']),\n",
        "       \"  -  quite a high, but somewhat non linear corelation. ? \\n\")\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juFUSX0RlnPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw5krUzE4iwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            WorkExp                    #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# WorkExp\n",
        "\n",
        "\n",
        "print (\"train_df :\")\n",
        "print( train_df.WorkExp.unique() )\n",
        "\n",
        "print (\"test_df :\")\n",
        "print ( test_df.WorkExp.unique() )\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoo6gNva-bm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workexpcount = 0\n",
        "workexpcounttest = 0 \n",
        "\n",
        "print (\" train contents counts\")\n",
        "print (\" train     test      WorkExp\")\n",
        "\n",
        "\n",
        "input= train_df.WorkExp.unique() \n",
        "strs = list(filter(lambda x : type(x) ==str,input))\n",
        "ints = list(filter(lambda x: type(x) == int, input))\n",
        "floats = list(filter(lambda x: type(x) == float, input))\n",
        "output = sorted(strs) + sorted(ints) + sorted(floats)\n",
        "\n",
        "\n",
        "for i in output :\n",
        "  thiscount = train_df.loc[train_df.WorkExp == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.WorkExp == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.WorkExp == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.WorkExp == i].Income.std()\n",
        "  workexpcount += thiscount\n",
        "  workexpcounttest += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismean, \"  ----  \", thisstd )\n",
        "print(\"sum of count   train : \", workexpcount, '   test : ', workexpcounttest )\n",
        "\n",
        "workexpcount2 = 0\n",
        "workexpcounttest2 = 0 \n",
        "\n",
        "print (\" test contents counts \")\n",
        "print (\" train     test      WorkExp\")\n",
        "\n",
        "input= test_df.WorkExp.unique() \n",
        "strs = list(filter(lambda x : type(x) ==str,input))\n",
        "ints = list(filter(lambda x: type(x) == int, input))\n",
        "floats = list(filter(lambda x: type(x) == float, input))\n",
        "output = sorted(strs) + sorted(ints) + sorted(floats)\n",
        "\n",
        "for i in output :\n",
        "  thiscount = train_df.loc[train_df.WorkExp == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.WorkExp == i].Instance.count()\n",
        "  thismeantest = train_df.loc[train_df.WorkExp == i].Income.mean()\n",
        "  thisstdtest = train_df.loc[train_df.WorkExp == i].Income.std()\n",
        "  workexpcount2 += thiscount\n",
        "  workexpcounttest2 += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismeantest, \"  ----  \", thisstdtest )\n",
        "print(\"sum of count   train : \", workexpcount2, '   test : ', workexpcounttest2 )\n",
        "\n",
        "print (float(2.0))\n",
        "print (float('2.0'))\n",
        "\n",
        "\n",
        "for i in [7.0, '7', 17.0, '17', 27.0, '27', 37.0, '37', '#NUM!'] : \n",
        "  print ( train_df.loc[train_df.WorkExp == i].Income.mean(), ' --- ', i, type(i) )\n",
        "\n",
        "print(dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zKKWFFGD7BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# string and number comparison \n",
        "# - have to be carefuel that python is not being too clever \n",
        "'''\n",
        "if 7.0 == '7.0' : \n",
        "  print ('Is equal!')\n",
        "else : \n",
        "  print ('not equal!')\n",
        "\n",
        "print(dt.now())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2VA0Mexyqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement mean encoding for WorkExp\n",
        "# what of teh two that are in test but not in train \n",
        "# which are 1.4 <class 'float'> & 47  <class 'str'>\n",
        "# either global mean encode or mean of either side - which - pref for more manual either side approach\n",
        "# initially just pick better of either side 47  <class 'str'>\n",
        "\n",
        "#build a map and then use it \n",
        "mean_encode = train_df.groupby('WorkExp')['Income'].mean()\n",
        "# print (mean_encode)\n",
        "# print (type(mean_encode))\n",
        "\n",
        "extras = pd.Series ([20259.65,56575.42], index=[1.4, '47'])\n",
        "# print (extras)\n",
        "\n",
        "mean_encode = mean_encode.append(extras)\n",
        "# print (mean_encode)\n",
        "# print (type(mean_encode))\n",
        "\n",
        "train_df.loc[:, 'WorkExpEnc1'] = train_df['WorkExp'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'WorkExpEnc1'] = test_df['WorkExp'].map(mean_encode)\n",
        "\n",
        "print (train_df.columns)\n",
        "print (test_df.columns)\n",
        "\n",
        "print (\"\\n 17 WorkExpEnc1 : \",\n",
        "       pearsonr(train_df[ 'WorkExpEnc1'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'WorkExpEnc1'], train_df['Income']),\n",
        "       \"  -  not much correlation despite mean encoding \\n\")\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fe2PDYuxyl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sAHKEqbxygH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode Work Exp as a scaled value : \n",
        "\n",
        "# WorkExp \n",
        "# encode as a scaled value \n",
        "\n",
        "'''\n",
        "print (\"Initial : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.WorkExpEnc1.max(), test_df.WorkExpEnc1.max())\n",
        "maxWorkExp = max(train_df.WorkExpEnc1.max(), test_df.WorkExpEnc1.max())\n",
        "print (\"    \", maxWorkExp) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.WorkExpEnc1.min(), test_df.WorkExpEnc1.min())\n",
        "minWorkExp = min(train_df.WorkExpEnc1.min(), test_df.WorkExpEnc1.min())\n",
        "print (\"    \", minWorkExp)\n",
        "\n",
        "rangeWorkExp = maxWorkExp - minWorkExp\n",
        "train_df.loc[:, 'WorkExpEnc'] = (train_df['WorkExpEnc']-minWorkExp) / rangeWorkExp\n",
        "\n",
        "test_df.loc[:, 'WorkExpEnc'] = (test_df['WorkExpEnc1']-minWorkExp) / rangeWorkExp\n",
        "\n",
        "print (\"\\nEncoded : \" )\n",
        "print (\"  max : \")\n",
        "print (\"    \", train_df.WorkExpEnc.max(), test_df.WorkExpEnc.max())\n",
        "maxWorkExpEnc = max(train_df.WorkExpEnc.max(), test_df.WorkExpEnc.max())\n",
        "print (\"    \", maxWorkExpEnc) \n",
        "\n",
        "print (\"  min : \")\n",
        "print (\"    \",train_df.WorkExpEnc.min(), test_df.WorkExpEnc.min())\n",
        "minWorkExpEnc = min(train_df.WorkExpEnc.min(), test_df.WorkExpEnc.min())\n",
        "print (\"    \", minWorkExpEnc)\n",
        "'''\n",
        "\n",
        "train_df[ 'WorkExpEnc'], test_df[ 'WorkExpEnc'] = myscale ( train_df.WorkExpEnc1, test_df.WorkExpEnc1 ) \n",
        "\n",
        "# and check correlation is preserved\n",
        "\n",
        "print (\" 5 WorkExp : \",\n",
        "       pearsonr(train_df[ 'WorkExpEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'WorkExpEnc'], train_df['Income']),\n",
        "       \"  -  slight corelation \\n\")\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZStymtxycg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            Satisfaction               #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# Satisfaction\n",
        "print (\"train_df :\")\n",
        "print( train_df.Satisfaction.unique() )\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print ( test_df.Satisfaction.unique() )\n",
        "\n",
        "print(\"\\n\", dt.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6VTzxZmPdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "satisfactioncount = 0\n",
        "satisfactioncounttest = 0\n",
        "\n",
        "for i in train_df.Satisfaction.unique() :\n",
        "  thiscount = train_df.loc[train_df.Satisfaction == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Satisfaction == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Satisfaction == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Satisfaction == i].Income.std()\n",
        "  satisfactioncount += thiscount\n",
        "  satisfactioncounttest += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismean, \"  ----  \", thisstd )\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", satisfactioncount, '   test : ', satisfactioncounttest )\n",
        "\n",
        "# replace the NANs with \"Undecided\"\n",
        "train_df[\"Satisfaction\"].fillna(\"Undecided\", inplace = True) \n",
        "test_df[\"Satisfaction\"].fillna(\"Undecided\", inplace = True) \n",
        "\n",
        "satisfactioncount = 0\n",
        "satisfactioncounttest = 0\n",
        "\n",
        "for i in train_df.Satisfaction.unique() :\n",
        "  thiscount = train_df.loc[train_df.Satisfaction == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Satisfaction == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Satisfaction == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Satisfaction == i].Income.std()\n",
        "  satisfactioncount += thiscount\n",
        "  satisfactioncounttest += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismean, \"  ----  \", thisstd )\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", satisfactioncount, '   test : ', satisfactioncounttest )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGCNTuBGmPPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use mean encoding - may adjust to a smoothed mean or James-Stein later\n",
        "\n",
        "#build a map and then use it \n",
        "mean_encode = train_df.groupby('Satisfaction')['Income'].mean()\n",
        "print (mean_encode)\n",
        "\n",
        "train_df.loc[:, 'SatisfactionEnc1'] = train_df['Satisfaction'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'SatisfactionEnc1'] = test_df['Satisfaction'].map(mean_encode)\n",
        "\n",
        "print (train_df.columns)\n",
        "print (test_df.columns)\n",
        "\n",
        "print (\"\\n 18 SatisfactionEnc1 : \",\n",
        "       pearsonr(train_df[ 'SatisfactionEnc1'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'SatisfactionEnc1'], train_df['Income']),\n",
        "       \"  -  Minimum correlation - could consider not using it - just adds noise. \\n\")\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icgXte5xmPCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the value\n",
        "train_df[ 'SatisfactionEnc'], test_df[ 'SatisfactionEnc'] = myscale ( train_df.SatisfactionEnc1, test_df.SatisfactionEnc1 ) \n",
        "\n",
        "\n",
        "\n",
        "print (\" 6 Satisfaction : \",\n",
        "       pearsonr(train_df[ 'SatisfactionEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'SatisfactionEnc'], train_df['Income']),\n",
        "       \"  -  Minimum correlation - could consider not using it - just adds noise. \\n\")\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwamLmKpmO0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title            Gender                     #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# Gender\n",
        "\n",
        "print (\" train_df :\")\n",
        "print( train_df.Gender.unique() )\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print ( test_df.Gender.unique() )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTLz9Ub1s9WH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check values and fill in NAs\n",
        "gendercount = 0\n",
        "gendercounttest = 0\n",
        "\n",
        "for i in train_df. Gender.unique() :\n",
        "  thiscount = train_df.loc[train_df.Gender == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Gender == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Gender == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Gender == i].Income.std()\n",
        "  gendercount += thiscount\n",
        "  gendercounttest += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismean, \"  ----  \", thisstd )\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", gendercount, '   test : ', gendercounttest )\n",
        "\n",
        "# replace the NANs with \"Missing\"\n",
        "train_df[\"Gender\"].fillna(\"Missing\", inplace = True) \n",
        "test_df[\"Gender\"].fillna(\"Missing\", inplace = True) \n",
        "\n",
        "gendercount = 0\n",
        "gendercounttest = 0\n",
        "\n",
        "for i in train_df.Gender.unique() :\n",
        "  thiscount = train_df.loc[train_df.Gender == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Gender == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Gender == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Gender == i].Income.std()\n",
        "  gendercount += thiscount\n",
        "  gendercounttest += thiscounttest\n",
        "  print ( thiscount, \" --- \", thiscounttest, \" --- \", i, type(i), \"  ----  \", thismean, \"  ----  \", thisstd )\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", gendercount, '   test : ', gendercounttest )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll1mSl5Fs9L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use mean encoding - may adjust to a smoothed mean or James-Stein later\n",
        "\n",
        "#build a map and then use it \n",
        "mean_encode = train_df.groupby('Gender')['Income'].mean()\n",
        "print (mean_encode)\n",
        "\n",
        "train_df.loc[:, 'GenderEnc1'] = train_df['Gender'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'GenderEnc1'] = test_df['Gender'].map(mean_encode)\n",
        "\n",
        "print (train_df.columns)\n",
        "print (test_df.columns)\n",
        "\n",
        "print (\"\\n 18 GenderEnc1 : \",\n",
        "       pearsonr(train_df[ 'GenderEnc1'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'GenderEnc1'], train_df['Income']),\n",
        "       \"  -  Small correlation - should contribute a bit. \\n\")\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGAtWUKDs899",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the value\n",
        "train_df[ 'GenderEnc'], test_df[ 'GenderEnc'] = myscale ( train_df.GenderEnc1, test_df.GenderEnc1 ) \n",
        "\n",
        "print (\" 7 Gender : \",\n",
        "       pearsonr(train_df[ 'GenderEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'GenderEnc'], train_df['Income']),\n",
        "       \"  -  Small correlation - should contribute a bit. \\n\")\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8yCXN8amOeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title           Country                     #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# Country\n",
        "\n",
        "print (\" train_df :\")\n",
        "print( train_df.Country.unique() )\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print ( test_df.Country.unique() )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f-6jAfYxyXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check values and fill in NAs\n",
        "countrycount = 0\n",
        "countrycounttest = 0\n",
        "\n",
        "print (\" train_df :\")\n",
        "for i in sorted( train_df.Country.unique().tolist() ) :\n",
        "  thiscount = train_df.loc[train_df.Country == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Country == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Country == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Country == i].Income.std()\n",
        "  countrycount += thiscount\n",
        "  countrycounttest += thiscounttest\n",
        "  print (\" -+++++++- \", thiscount + thiscounttest, \" -+- \", thiscount, \" -++- \", thiscounttest, \" -+++- \", i, type(i), \" -++++- \", thismean, \" -+++++- \", thisstd, \" -++++++- \" )\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", countrycount, '   test : ', countrycounttest )\n",
        "\n",
        "# replace the NANs with \"Missing\"\n",
        "# train_df[\"Country\"].fillna(\"Unknown\", inplace = True) \n",
        "test_df[\"Country\"].fillna(\"Unknown\", inplace = True) \n",
        "\n",
        "countrycount = 0\n",
        "countrycounttest = 0\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "for i in sorted( test_df.Country.unique().tolist() ) :\n",
        "  thiscount = train_df.loc[train_df.Country == i].Instance.count()\n",
        "  thiscounttest = test_df.loc[test_df.Country == i].Instance.count()\n",
        "  thismean = train_df.loc[train_df.Country == i].Income.mean()\n",
        "  thisstd = train_df.loc[train_df.Country == i].Income.std()\n",
        "  countrycount += thiscount\n",
        "  countrycounttest += thiscounttest\n",
        "  print ( \" -+++++++- \", thiscount + thiscounttest, \" -+- \", thiscount, \" -++- \", thiscounttest, \" -+++- \", i, type(i), \" -++++- \", thismean, \" -+++++- \", thisstd, \" -++++++- \")\n",
        "\n",
        "print(\"record count   train : \", len(train_df.Instance), '   test : ', len(test_df.Instance) )\n",
        "print(\"sum of count   train : \", countrycount, '   test : ', countrycounttest )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tDsy8kfbRRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode using mean encoding and also use a total count encoding \n",
        "# for countries only in test use overall mean - and hope that the count picks \n",
        "# it up - would be tempting to use a mean for a country with a similar count.\n",
        "\n",
        "# means for countries with similar counts (or equal for lower counts)\n",
        "# for all countries missing in train_df\n",
        "\n",
        "'''\n",
        "Egypt\t484811.7491\n",
        "United Kingdom\t573221.8324\n",
        "Unknown\t484811.7491\n",
        "Uruguay\t158495.8342\n",
        "Uzbekistan\t278893.7784\n",
        "Vanuatu\t414758.4535\n",
        "Venezuela\t239445.9115\n",
        "Vietnam\t484811.7491\n",
        "Yemen\t250653.3961\n",
        "Zambia\t165889.0433\n",
        "Zimbabwe\t137950.3644\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P82PpJQFbRJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build a map and then use it \n",
        "mean_encode = train_df.groupby('Country')['Income'].mean()\n",
        "\n",
        "# print(type(mean_encode))\n",
        "# print (mean_encode)\n",
        "\n",
        "# build a map for the contries not in train (values derived based on nearest neighbours by count)\n",
        "extra_encode = pd.Series ([484811.7491, 573221.8324, 484811.7491,\n",
        "                           158495.8342, 278893.7784, 414758.4535,\n",
        "                           239445.9115, 484811.7491,250653.3961,\n",
        "                           165889.0433, 137950.3644],\n",
        "                    index=[\"Egypt\", \"United Kingdom\", \"Unknown\",\n",
        "                           \"Uruguay\", \"Uzbekistan\", \"Vanuatu\",\n",
        "                           \"Venezuela\", \"Vietnam\", \"Yemen\",\n",
        "                           \"Zambia\", \"Zimbabwe\"])\n",
        "\n",
        "#combine the two maps\n",
        "mean_encode = mean_encode.append(extra_encode, verify_integrity=True)\n",
        "\n",
        "# print(type(mean_encode))\n",
        "# print (mean_encode)\n",
        "\n",
        "\n",
        "train_df.loc[:, 'CountryEnc1'] = train_df['Country'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'CountryEnc1'] = test_df['Country'].map(mean_encode)\n",
        "\n",
        "print (\" train_df :\")\n",
        "print ( train_df['CountryEnc1'].describe() )\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print ( test_df['CountryEnc1'].describe() )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2YctmPmbRB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a map and encode county count as well \n",
        "\n",
        "#build a map and then use it \n",
        "mean_encode1 = train_df.groupby('Country')['Instance'].count()\n",
        "\n",
        "# print(type(mean_encode))\n",
        "# print (mean_encode)\n",
        "\n",
        "# build a map for the contries not in train (values derived based on nearest neighbours by count)\n",
        "extra_encode1 = pd.Series ([0,0,0,\n",
        "                            0,0,0,\n",
        "                            0,0,0,\n",
        "                            0,0],\n",
        "                    index=[\"Egypt\", \"United Kingdom\", \"Unknown\",\n",
        "                           \"Uruguay\", \"Uzbekistan\", \"Vanuatu\",\n",
        "                           \"Venezuela\", \"Vietnam\", \"Yemen\",\n",
        "                           \"Zambia\", \"Zimbabwe\"])\n",
        "\n",
        "mean_encode2 = test_df.groupby('Country')['Instance'].count()\n",
        "\n",
        "\n",
        "\n",
        "#combine the two maps\n",
        "mean_encode1 = mean_encode1.append(extra_encode1, verify_integrity=True)\n",
        "\n",
        "mean_encode = mean_encode1.add(mean_encode2, fill_value=0)\n",
        "\n",
        "# print(type(mean_encode))\n",
        "print (mean_encode)\n",
        "\n",
        "\n",
        "train_df.loc[:, 'CountryEnc2'] = train_df['Country'].map(mean_encode)\n",
        "\n",
        "test_df.loc[:, 'CountryEnc2'] = test_df['Country'].map(mean_encode)\n",
        "\n",
        "print (\" train_df :\")\n",
        "print ( train_df['CountryEnc2'].describe() )\n",
        "\n",
        "print (\"\\n test_df :\")\n",
        "print ( test_df['CountryEnc2'].describe() )\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYHYbydKbQ6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check correlation of both - and also with each other\n",
        "\n",
        "\n",
        "print (\" 8 Country : \",\n",
        "       pearsonr(train_df[ 'CountryEnc1'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEnc1'], train_df['Income']),\n",
        "       \"  -  some linear correlation. \\n\")\n",
        "\n",
        "print (\" 8 Country Count : \",\n",
        "       pearsonr(train_df[ 'CountryEnc2'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEnc2'], train_df['Income']),\n",
        "       \"  -  less correlation and more non-linear \\n\")\n",
        "\n",
        "print (\" 8 Country : \",\n",
        "       pearsonr(train_df[ 'CountryEnc1'], train_df['CountryEnc2']),\n",
        "       spearmanr(train_df[ 'CountryEnc1'], train_df['CountryEnc2']),\n",
        "       \"  -  Moderate linear correlation between the two - better non linear one  - could be that one would do \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpYUKuJNbQye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale both and recheck correlations\n",
        "\n",
        "# Scale the value\n",
        "train_df[ 'CountryEncA'], test_df[ 'CountryEncA'] = myscale ( train_df.CountryEnc1, test_df.CountryEnc1 ) \n",
        "\n",
        "print (\" 8 Country : \",\n",
        "       pearsonr(train_df[ 'CountryEncA'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEncA'], train_df['Income']),\n",
        "       \"  -   \\n\")\n",
        "\n",
        "# Scale the value\n",
        "train_df[ 'CountryEncB'], test_df[ 'CountryEncB'] = myscale ( train_df.CountryEnc2, test_df.CountryEnc2 ) \n",
        "\n",
        "print (\" 8 Country Count : \",\n",
        "       pearsonr(train_df[ 'CountryEncB'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEncB'], train_df['Income']),\n",
        "       \"  -   \\n\")\n",
        "\n",
        "print(\"\\n\", dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HQ10YcsbQqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmWFUMACbQgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-77GZVkjk6JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z6F_My1k59D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWYjOhQEbQU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DMam6JobQHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "#@title       Correlation Review              #\n",
        "###############################################\n",
        "\n",
        "\n",
        "# Review the correlations \n",
        "\n",
        "print (\" 0 Instance : \",\n",
        "       pearsonr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       \"  -  quite high, but somewhat non linear corelation. Why ? \\n\")\n",
        "\t   \n",
        "print (\" 1 Year : \",\n",
        "       pearsonr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'YearEnc'], train_df['Income']),\n",
        "       \"  -  quite high, but somewhat non linear corelation. Why ? \\n\")\n",
        "\n",
        "print (\" 2 Housing : \",\n",
        "       pearsonr(train_df[ 'HousingEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'HousingEnc'], train_df['Income']),\n",
        "       \"  -  quite high, but somewhat non linear corelation. ? \\n\")\n",
        "\t\n",
        "print (\" 3 CrimeLevel : \",\n",
        "       pearsonr(train_df[ 'CrimeLevel'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CrimeLevel'], train_df['Income']),\n",
        "       \"  -  Very little corelation - don't use this data. \\n\")\n",
        "\t   \n",
        "print (\" 4 Age: \",\n",
        "       pearsonr(train_df[ 'Age'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'Age'], train_df['Income']),\n",
        "       \"  -  Very little corelation. Use ? \\n\")\t   \n",
        "\t   \n",
        "print (\" 5 WorkExp : \",\n",
        "       pearsonr(train_df[ 'WorkExpEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'WorkExpEnc'], train_df['Income']),\n",
        "       \"  -  slight corelation \\n\")\n",
        "\t   \n",
        "print (\" 6 Satisfaction : \",\n",
        "       pearsonr(train_df[ 'SatisfactionEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'SatisfactionEnc'], train_df['Income']),\n",
        "       \"  -  Minimum correlation - could consider not using it - just adds noise. \\n\")\n",
        "\n",
        "print (\" 7 Gender : \",\n",
        "       pearsonr(train_df[ 'GenderEnc'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'GenderEnc'], train_df['Income']),\n",
        "       \"  -  Small correlation - should contribute a bit. \\n\")\n",
        "\n",
        "print (\" 8 Country  : \",\n",
        "       pearsonr(train_df[ 'CountryEncA'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEncA'], train_df['Income']),\n",
        "       \"  -   \\n\")\n",
        "\n",
        "print (\"(8) Country Count : \",\n",
        "       pearsonr(train_df[ 'CountryEncB'], train_df['Income']),\n",
        "       spearmanr(train_df[ 'CountryEncB'], train_df['Income']),\n",
        "       \"  -   \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27glrH5xySZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the encoded numeric columns into our training data set\n",
        "\n",
        "train_df_num = train_df[[\"InstanceEnc\",\n",
        "                         \"YearEnc\",\n",
        "                         \"HousingEnc\",\n",
        "                         \"WorkExpEnc\",\n",
        "                         # \"SatisfactionEnc\",\n",
        "                         \"GenderEnc\",\n",
        "                         \"CountryEncA\",\n",
        "                         # \"CountryEncB\"\n",
        "                         ]] \n",
        "\n",
        "# include the known dependant variable values (the thing we are trying to predict)\n",
        "\n",
        "train_df_num['Income'] = train_df['Income']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblecavVxyM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_norm =  train_df[[\"InstanceEnc\",\n",
        "                        \"YearEnc\",\n",
        "                        \"HousingEnc\",\n",
        "                        \"WorkExpEnc\",\n",
        "                        \"SatisfactionEnc\",\n",
        "                        \"GenderEnc\",\n",
        "                        \"CountryEncA\",\n",
        "                        \"CountryEncB\"]] \n",
        "\n",
        "y_full = train_df[\"Income\"].copy()\n",
        "miny = y_full.min()\n",
        "maxy = y_full.max()\n",
        "y_norm = (y_full.copy() - miny +1 )/ (maxy - miny + 1)                         \n",
        "\n",
        "print (train_norm.shape, y_norm.shape)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGNu8jgY2onP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyK-jIHAxyGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Setting up train and test sets\")\n",
        "\n",
        "df = train_norm.copy()\n",
        "\n",
        "X_train1 = df.copy()\n",
        "y_train1norm = y_norm.copy()\n",
        "\n",
        "X_train2, X_test2, y_train2norm, y_test2norm = train_test_split(df, y_norm, test_size=0.20)\n",
        "\n",
        "X_train3, X_test3, y_train3norm, y_test3norm = train_test_split(df, y_norm, test_size=0.20)\n",
        "\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZUoKdl54rI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"reasembling the un-normalised test sets\")\n",
        "\n",
        "y_train1  = ((y_train1norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "\n",
        "\n",
        "y_train2 = ((y_train2norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "y_test2 = ((y_test2norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "\n",
        "y_train3 = ((y_train3norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "y_test3 = ((y_test3norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "\n",
        "print ('y_train1 after  : ', y_train1.shape)\n",
        "\n",
        "print ('y_train2 after  : ', y_train2.shape)\n",
        "print ('y_test2 after  : ', y_test2.shape)\n",
        "\n",
        "\n",
        "print ('y_train3 after  : ', y_train3.shape)\n",
        "print ('y_test3 after  : ', y_test3.shape)\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CiBychY5uLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run before from here to set up data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZMJtfozxxwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model using the available data : \n",
        "\n",
        "# Currently 6 : \n",
        "# InstanceEnc \n",
        "# YearEnc \n",
        "# HousingEnc\n",
        "# WorkExpEnc\n",
        "# SatisfactionEnc\n",
        "# GenderEnc\n",
        "\n",
        "modelwidth = 20\n",
        "\n",
        "k1model = Sequential()\n",
        "k1model.add(Dense(units=modelwidth, activation='elu', input_dim=6))\n",
        "k1model.add(Dense(units=modelwidth, activation='relu'))\n",
        "k1model.add(Dense(units=modelwidth, activation='softmax'))\n",
        "k1model.add(Dense(units=1, activation=\"linear\"))\n",
        "k1model.compile(loss=\"mse\", optimizer=Adam(lr=1e-4, decay=1e-4 / 200))\n",
        "\n",
        "\n",
        "k2model = Sequential()\n",
        "k2model.add(Dense(units=modelwidth, activation='elu', input_dim=6))\n",
        "k2model.add(Dense(units=modelwidth, activation='relu'))\n",
        "k2model.add(Dense(units=modelwidth, activation='softmax'))\n",
        "k2model.add(Dense(units=1, activation=\"linear\"))\n",
        "k2model.compile(loss=\"mse\", optimizer=Adam(lr=1e-4, decay=1e-4 / 200))\n",
        "\n",
        "k3model = Sequential()\n",
        "k3model.add(Dense(units=modelwidth, activation='elu', input_dim=6))\n",
        "k3model.add(Dense(units=modelwidth, activation='relu'))\n",
        "k3model.add(Dense(units=modelwidth, activation='softmax'))\n",
        "k3model.add(Dense(units=1, activation=\"linear\"))\n",
        "k3model.compile(loss=\"mse\", optimizer=Adam(lr=1e-4, decay=1e-4 / 200))\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxg0KCIn5p8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run before here to complete data setup and model compilaton"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnOTldgN5hPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dt.now())\n",
        "\n",
        "pred_bat_sz = 32768\n",
        "\n",
        "epcs = 150     # number of measurement cycles \n",
        "mini_epcs = 1   # number of actual epochs pers measurement cycle\n",
        "# actual number of epochs is the product of these two\n",
        "\n",
        "big_bat_sz = 2048\n",
        "nudge_bat_sz = 32\n",
        "# nudges = [100,200,300,400,500,600,700,800,900]\n",
        "# nudges = [50,60,70,80,90]\n",
        "nudges = [10,20,30,40,50,60,70,80,90]\n",
        "#nudges = [10,20]\n",
        "rmsetrain1 = np.zeros(epcs)\n",
        "rmsetrain2 = np.zeros(epcs)\n",
        "rmsetest2  = np.zeros(epcs)\n",
        "rmsetrain3 = np.zeros(epcs)\n",
        "rmsetest3  = np.zeros(epcs)\n",
        "\n",
        "print ( 'Epochs =', epcs*mini_epcs, '   Batch Size =', big_bat_sz, '   Measurement Cycles =',epcs)\n",
        "print ( 'Nudges at Epochs :', nudges , '   Nudge Batch Size =', nudge_bat_sz )\n",
        "\n",
        "for i in range (epcs) :\n",
        "\n",
        "  if i in nudges :\n",
        "    bat_sz = nudge_bat_sz\n",
        "    print(\"-- nudge --\")\n",
        "  else : \n",
        "    bat_sz = big_bat_sz\n",
        "\n",
        "  k3model.fit(X_train3, y_train3norm, epochs=mini_epcs, batch_size=bat_sz, verbose=0)\n",
        "\n",
        "  ypred3norm = k3model.predict(X_train3, batch_size=pred_bat_sz)\n",
        "  ypred3 = ((ypred3norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "  ktrain3RMS = sqrt ( mean_squared_error(y_train3, ypred3))\n",
        "\n",
        "  ytestpred3norm = k3model.predict(X_test3, batch_size=bat_sz)\n",
        "  ytestpred3 = ((ytestpred3norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "  ktest3RMS = sqrt ( mean_squared_error(y_test3, ytestpred3))\n",
        "  # print (' 80-20 split :  RMSE-Train ', ktrain3RMS, ' RMSE_Test ', ktest3RMS)\n",
        "\n",
        "  k2model.fit(X_train2, y_train2norm, epochs=mini_epcs, batch_size=bat_sz, verbose=0)\n",
        "\n",
        "  ypred2norm = k2model.predict(X_train2, batch_size=pred_bat_sz)\n",
        "  ypred2 = ((ypred2norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "  ktrain2RMS = sqrt ( mean_squared_error(y_train2, ypred2))\n",
        "\n",
        "  ytestpred2norm = k2model.predict(X_test2, batch_size=bat_sz)\n",
        "  ytestpred2 = ((ytestpred2norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "  ktest2RMS = sqrt ( mean_squared_error(y_test2, ytestpred2))\n",
        "  # print (' 88-12 split :  RMSE-Train ', ktrain2RMS, ' RMSE_Test ', ktest2RMS)\n",
        "\n",
        "  k1model.fit(X_train1, y_train1norm, epochs=mini_epcs, batch_size=bat_sz, verbose=0)\n",
        "\n",
        "  ypred1norm = k1model.predict(X_train1, batch_size=pred_bat_sz)\n",
        "  ypred1 = ((ypred1norm.copy() * (maxy - miny + 1)) + miny -1)\n",
        "  ktrain1RMS = sqrt ( mean_squared_error(y_train1, ypred1))\n",
        "  # print (' 100% train :  RMSE-Train ', ktrain1RMS)\n",
        "\n",
        "  rmsetrain1[i] = ktrain1RMS\n",
        "  rmsetrain2[i] = ktrain2RMS\n",
        "  rmsetest2[i]  = ktest2RMS\n",
        "  rmsetrain3[i] = ktrain3RMS\n",
        "  rmsetest3[i]  = ktest3RMS\n",
        "\n",
        "  print (i, dt.now(),\n",
        "         '  100% train :  RMSE-Train ', int(ktrain1RMS), \n",
        "         ' 80-20 split :  RMSE-Train ', int(ktrain2RMS), \n",
        "         ' RMSE_Test ', int(ktest2RMS), \n",
        "         ' 80-20 -2 split :  RMSE-Train ', int(ktrain3RMS), \n",
        "         ' RMSE_Test ', int(ktest3RMS),\n",
        "         '  ', int(ktrain1RMS) - int(rmsetrain1[0]),\n",
        "         '    ', int(ktrain2RMS) - int(rmsetrain2[0]),\n",
        "         ' ', int(ktest2RMS) - int(rmsetest2[0]),                      \n",
        "         '    ', int(ktrain3RMS) - int(rmsetrain3[0]),\n",
        "         ' ', int(ktest3RMS) - int(rmsetest3[0]) ) \n",
        "  \n",
        " \n",
        "\n",
        "  # END for\n",
        "\n",
        "print(dt.now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oebA0uKz6Hiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = range(epcs)\n",
        "\n",
        "hline1value = 50000\n",
        "hline2value = 49000\n",
        "hline3value = 49500\n",
        "hline1 = np.zeros(epcs)\n",
        "hline1 = hline1 + hline1value\n",
        "hline2 = np.zeros(epcs)\n",
        "hline2 = hline2 + hline2value\n",
        "hline3 = np.zeros(epcs)\n",
        "hline3 = hline3 + hline3value\n",
        "plt.figure(figsize=(24,12), dpi=80)  \n",
        "plt.plot (x, rmsetrain3, color='cyan',  label=\"train 3 -  80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain2, color='pink',  label=\"train 2 -  80%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain1, color='green', label=\"train 1 - 100%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest3, color='blue',  label=\"test 3 - 80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest2, color='red',   label=\"test 2 - 80%\",linewidth=0.5)\n",
        "plt.plot (x, hline1, color='grey', label = str(hline1value),linewidth=0.5)\n",
        "plt.plot (x, hline2, color='grey', label = str(hline2value),linewidth=0.5)\n",
        "plt.plot (x, hline3, color='black', label = str(hline3value),linewidth=0.5)\n",
        "plt.legend();\n",
        "plt.title(\"2 : Looking for overfitting point   batch= \" + str(bat_sz) + \"   epochs= \" + str(epcs*mini_epcs) + \"  (\" + str(mini_epcs) + \" per iteration)\")\n",
        "plt.xlabel(\"model iterations\")\n",
        "plt.ylabel(\"Root Mean Square Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91QD_KOAEqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = range(epcs)\n",
        "\n",
        "hline1value = 50000\n",
        "hline2value = 49000\n",
        "hline3value = 49500\n",
        "hline1 = np.zeros(epcs)\n",
        "hline1 = hline1 + hline1value\n",
        "hline2 = np.zeros(epcs)\n",
        "hline2 = hline2 + hline2value\n",
        "hline3 = np.zeros(epcs)\n",
        "hline3 = hline3 + hline3value\n",
        "plt.figure(figsize=(24,12), dpi=80)  \n",
        "plt.plot (x, rmsetrain3, color='cyan',  label=\"train 3 -  80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain2, color='pink',  label=\"train 2 -  80%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain1, color='green', label=\"train 1 - 100%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest3, color='blue',  label=\"test 3 - 80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest2, color='red',   label=\"test 2 - 80%\",linewidth=0.5)\n",
        "plt.plot (x, hline1, color='grey', label = str(hline1value),linewidth=0.5)\n",
        "plt.plot (x, hline2, color='grey', label = str(hline2value),linewidth=0.5)\n",
        "plt.plot (x, hline3, color='black', label = str(hline3value),linewidth=0.5)\n",
        "plt.legend();\n",
        "plt.title(\"2 : Looking for overfitting point   batch= \" + str(bat_sz) + \"   epochs= \" + str(epcs*mini_epcs) + \"  (\" + str(mini_epcs) + \" per iteration)\")\n",
        "plt.xlabel(\"model iterations\")\n",
        "plt.ylabel(\"Root Mean Square Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBzhH4T9aV7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = range(epcs)\n",
        "\n",
        "hline1value = 50500\n",
        "hline2value = 49000\n",
        "hline3value = 49750\n",
        "hline1 = np.zeros(epcs)\n",
        "hline1 = hline1 + hline1value\n",
        "hline2 = np.zeros(epcs)\n",
        "hline2 = hline2 + hline2value\n",
        "hline3 = np.zeros(epcs)\n",
        "hline3 = hline3 + hline3value\n",
        "plt.figure(figsize=(24,12), dpi=80)  \n",
        "plt.plot (x, rmsetrain3, color='cyan',  label=\"train 3 -  80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain2, color='pink',  label=\"train 2 -  80%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain1, color='green', label=\"train 1 - 100%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest3, color='blue',  label=\"test 3 - 80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest2, color='red',   label=\"test 2 - 80%\",linewidth=0.5)\n",
        "plt.plot (x, hline1, color='grey', label = str(hline1value),linewidth=0.5)\n",
        "plt.plot (x, hline2, color='grey', label = str(hline2value),linewidth=0.5)\n",
        "plt.plot (x, hline3, color='black', label = str(hline3value),linewidth=0.5)\n",
        "plt.legend();\n",
        "plt.title(\"2 : Looking for overfitting point   batch= \" + str(bat_sz) + \"   epochs= \" + str(epcs*mini_epcs) + \"  (\" + str(mini_epcs) + \" per iteration)\")\n",
        "plt.xlabel(\"model iterations\")\n",
        "plt.ylabel(\"Root Mean Square Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfFP47qEluD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = range(epcs)\n",
        "\n",
        "hline1value = 50000\n",
        "hline2value = 49000\n",
        "hline3value = 49500\n",
        "hline1 = np.zeros(epcs)\n",
        "hline1 = hline1 + hline1value\n",
        "hline2 = np.zeros(epcs)\n",
        "hline2 = hline2 + hline2value\n",
        "hline3 = np.zeros(epcs)\n",
        "hline3 = hline3 + hline3value\n",
        "plt.figure(figsize=(24,12), dpi=80)  \n",
        "plt.plot (x, rmsetrain3, color='cyan',  label=\"train 3 -  80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain2, color='pink',  label=\"train 2 -  80%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetrain1, color='green', label=\"train 1 - 100%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest3, color='blue',  label=\"test 3 - 80B%\",linewidth=0.5)\n",
        "plt.plot (x, rmsetest2, color='red',   label=\"test 2 - 80%\",linewidth=0.5)\n",
        "# plt.plot (x, hline1, color='grey', label = str(hline1value),linewidth=0.5)\n",
        "# plt.plot (x, hline2, color='grey', label = str(hline2value),linewidth=0.5)\n",
        "# plt.plot (x, hline3, color='black', label = str(hline3value),linewidth=0.5)\n",
        "plt.legend();\n",
        "plt.title(\"2 : Looking for overfitting point   batch= \" + str(bat_sz) + \"   epochs= \" + str(epcs*mini_epcs) + \"  (\" + str(mini_epcs) + \" per iteration)\")\n",
        "plt.xlabel(\"model iterations\")\n",
        "plt.ylabel(\"Root Mean Square Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBOhMi1ll0Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps = [3,7]\n",
        "\n",
        "for i in range (10) :\n",
        "  print (i,)\n",
        "  if i in steps :\n",
        "    print (\" This is a step.\")\n",
        "  else : \n",
        "    print (\".\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}